
@article{noauthor_retracted:_2023,
	title = {Retracted: {Network} {Traffic} {Prediction} via {Deep} {Graph}-{Sequence} {Spatiotemporal} {Modeling} {Based} on {Mobile} {Virtual} {Reality} {Technology}},
	volume = {2023},
	issn = {1530-8669, 1530-8677},
	shorttitle = {Retracted},
	url = {https://www.hindawi.com/journals/wcmc/2023/9806091/},
	doi = {10.1155/2023/9806091},
	language = {en},
	urldate = {2024-05-01},
	journal = {Wireless Communications and Mobile Computing},
	month = nov,
	year = {2023},
	pages = {1--1},
}

@article{lohrasbinasab_statistical_2022,
	title = {From statistical‐ to machine learning‐based network traffic prediction},
	volume = {33},
	issn = {2161-3915, 2161-3915},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/ett.4394},
	doi = {10.1002/ett.4394},
	abstract = {Abstract
            
              Nowadays, due to the exponential and continuous expansion of new paradigms such as Internet of Things (IoT), Internet of Vehicles (IoV) and 6G, the world is witnessing a tremendous and sharp increase of network traffic. In such large‐scale, heterogeneous, and complex networks, the volume of transferred data, as
              big data
              , is considered a challenge causing different networking inefficiencies. To overcome these challenges, various techniques are introduced to monitor the performance of networks, called Network Traffic Monitoring and Analysis (NTMA). Network Traffic Prediction (NTP) is a significant subfield of NTMA which is mainly focused on predicting the future of network load and its behavior. NTP techniques can generally be realized in two ways, that is, statistical‐ and Machine Learning (ML)‐based. In this paper, we provide a study on existing NTP techniques through reviewing, investigating, and classifying the recent relevant works conducted in this field. Additionally, we discuss the challenges and future directions of NTP showing that how ML and statistical techniques can be used to solve challenges of NTP.},
	language = {en},
	number = {4},
	urldate = {2024-05-01},
	journal = {Transactions on Emerging Telecommunications Technologies},
	author = {Lohrasbinasab, Iraj and Shahraki, Amin and Taherkordi, Amir and Delia Jurcut, Anca},
	month = apr,
	year = {2022},
	pages = {e4394},
}

@article{jiang_graph_2022,
	title = {Graph neural network for traffic forecasting: {A} survey},
	volume = {207},
	issn = {09574174},
	shorttitle = {Graph neural network for traffic forecasting},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417422011654},
	doi = {10.1016/j.eswa.2022.117921},
	language = {en},
	urldate = {2024-05-01},
	journal = {Expert Systems with Applications},
	author = {Jiang, Weiwei and Luo, Jiayun},
	month = nov,
	year = {2022},
	pages = {117921},
}

@article{liu_scientometric_2021,
	title = {A scientometric review of research on traffic forecasting in transportation},
	volume = {15},
	copyright = {http://creativecommons.org/licenses/by/4.0/},
	issn = {1751-956X, 1751-9578},
	url = {https://onlinelibrary.wiley.com/doi/10.1049/itr2.12024},
	doi = {10.1049/itr2.12024},
	language = {en},
	number = {1},
	urldate = {2024-05-01},
	journal = {IET Intelligent Transport Systems},
	author = {Liu, Jin and Wu, Naiqi and Qiao, Yan and Li, Zhiwu},
	month = jan,
	year = {2021},
	pages = {1--16},
}

@article{mozo_forecasting_2018,
	title = {Forecasting short-term data center network traffic load with convolutional neural networks},
	volume = {13},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0191939},
	doi = {10.1371/journal.pone.0191939},
	language = {en},
	number = {2},
	urldate = {2024-05-01},
	journal = {PLOS ONE},
	author = {Mozo, Alberto and Ordozgoiti, Bruno and Gómez-Canaval, Sandra},
	editor = {Yang, Jinn-Moon},
	month = feb,
	year = {2018},
	pages = {e0191939},
}

@incollection{de_francisci_morales_circle_2023,
	address = {Cham},
	title = {Circle {Attention}: {Forecasting} {Network} {Traffic} by {Learning} {Interpretable} {Spatial} {Relationships} from {Intersecting} {Circles}},
	volume = {14175},
	isbn = {9783031434297 9783031434303},
	shorttitle = {Circle {Attention}},
	url = {https://link.springer.com/10.1007/978-3-031-43430-3_7},
	language = {en},
	urldate = {2024-05-01},
	booktitle = {Machine {Learning} and {Knowledge} {Discovery} in {Databases}: {Applied} {Data} {Science} and {Demo} {Track}},
	publisher = {Springer Nature Switzerland},
	author = {Haugsdal, Espen and Malacarne, Sara and Ruocco, Massimiliano},
	editor = {De Francisci Morales, Gianmarco and Perlich, Claudia and Ruchansky, Natali and Kourtellis, Nicolas and Baralis, Elena and Bonchi, Francesco},
	year = {2023},
	doi = {10.1007/978-3-031-43430-3_7},
	pages = {106--121},
}

@article{kramar_time-series_2023,
	title = {Time-{Series} {Forecasting} of {Seasonal} {Data} {Using} {Machine} {Learning} {Methods}},
	volume = {16},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1999-4893},
	url = {https://www.mdpi.com/1999-4893/16/5/248},
	doi = {10.3390/a16050248},
	abstract = {The models for forecasting time series with seasonal variability can be used to build automatic real-time control systems. For example, predicting the water flowing in a wastewater treatment plant can be used to calculate the optimal electricity consumption. The article describes a performance analysis of various machine learning methods (SARIMA, Holt-Winters Exponential Smoothing, ETS, Facebook Prophet, XGBoost, and Long Short-Term Memory) and data-preprocessing algorithms implemented in Python. The general methodology of model building and the requirements of the input data sets are described. All models use actual data from sensors of the monitoring system. The novelty of this work is in an approach that allows using limited history data sets to obtain predictions with reasonable accuracy. The implemented algorithms made it possible to achieve an R-Squared accuracy of more than 0.95. The forecasting calculation time is minimized, which can be used to run the algorithm in real-time control and embedded systems.},
	language = {en},
	number = {5},
	urldate = {2024-05-01},
	journal = {Algorithms},
	author = {Kramar, Vadim and Alchakov, Vasiliy},
	month = may,
	year = {2023},
	pages = {248},
}

@misc{sabatti_computer_nodate,
	title = {Computer {Network} {Traffic} {Data}},
	url = {https://chiarasabatti.su.domains/data.html},
	journal = {Chiarasabatti.su},
	author = {Sabatti, Chiara},
}

@article{hochreiter_long_1997,
	title = {Long {Short}-{Term} {Memory}},
	volume = {9},
	issn = {0899-7667, 1530-888X},
	url = {https://direct.mit.edu/neco/article/9/8/1735-1780/6109},
	doi = {10.1162/neco.1997.9.8.1735},
	abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
	language = {en},
	number = {8},
	urldate = {2024-05-01},
	journal = {Neural Computation},
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	month = nov,
	year = {1997},
	pages = {1735--1780},
}

@inproceedings{gers_learning_1999,
	address = {Edinburgh, UK},
	title = {Learning to forget: continual prediction with {LSTM}},
	volume = {1999},
	isbn = {9780852967218},
	shorttitle = {Learning to forget},
	url = {https://digital-library.theiet.org/content/conferences/10.1049/cp_19991218},
	doi = {10.1049/cp:19991218},
	language = {en},
	urldate = {2024-05-01},
	booktitle = {9th {International} {Conference} on {Artificial} {Neural} {Networks}: {ICANN} '99},
	publisher = {IEE},
	author = {Gers, F.A.},
	year = {1999},
	pages = {850--855},
}

@article{bhandari_predicting_2022,
	title = {Predicting stock market index using {LSTM}},
	volume = {9},
	issn = {26668270},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2666827022000378},
	doi = {10.1016/j.mlwa.2022.100320},
	language = {en},
	urldate = {2024-05-01},
	journal = {Machine Learning with Applications},
	author = {Bhandari, Hum Nath and Rimal, Binod and Pokhrel, Nawa Raj and Rimal, Ramchandra and Dahal, Keshab R. and Khatri, Rajendra K.C.},
	month = sep,
	year = {2022},
	pages = {100320},
}

@article{zhang_network_2021,
	title = {Network {Traffic} {Prediction} via {Deep} {Graph}-{Sequence} {Spatiotemporal} {Modeling} {Based} on {Mobile} {Virtual} {Reality} {Technology}},
	volume = {2021},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1530-8677, 1530-8669},
	url = {https://www.hindawi.com/journals/wcmc/2021/2353875/},
	doi = {10.1155/2021/2353875},
	abstract = {Accurate and real-time network traffic flow forecast holds an important role for network management. Especially at present, virtual reality (VR), artificial intelligence (AI), vehicle-to-everything (V2X), and other technologies are closely combined through the mobile network, which greatly increases the human-computer interaction activities. At the same time, it requires high-throughput, low delay, and high reliable service guarantee. In order to achieve ondemand real-time high-quality network service, we must accurately grasp the dynamic changes of network traffic. However, due to the increase of client mobility and application behavior diversity, the complexity and dynamics of network traffic in the temporal domain and the spatial domain increase sharply. To accurate capture the spatiotemporal features, we propose the spatial-temporal graph convolution gated recurrent unit (GC-GRU) model, which integrates the graph convolutional network (GCN) and the gated recurrent unit (GRU) together. In this model, the GCN structure could handle the spatial features of traffic flow with network topology, and the GRU is used to further process spatiotemporal features. Experiments show that the GC-GRU model has better prediction performance than other baseline models and can obtain spatial-temporal correlation in traffic lows better.},
	language = {en},
	urldate = {2024-05-01},
	journal = {Wireless Communications and Mobile Computing},
	author = {Zhang, Kai and Zhao, Xiaohu and Li, Xiao and You, XingYi and Zhu, Yonghong},
	editor = {Nagaraj, Balakrishnan},
	month = jul,
	year = {2021},
	pages = {1--12},
}

@misc{khodadadi_traffic_2021,
	title = {Traffic {Forecasting} {Using} {Graph} {Neural} {Networks} and {LSTM}},
	url = {https://keras.io/examples/timeseries/timeseries_traffic_forecasting/},
	journal = {keras.io},
	author = {Khodadadi, Arash},
	year = {2021},
}

@inproceedings{nihale_network_2020,
	address = {Coimbatore, India},
	title = {Network {Traffic} {Prediction} {Using} {Long} {Short}-{Term} {Memory}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {9781728141084},
	url = {https://ieeexplore.ieee.org/document/9156045/},
	doi = {10.1109/ICESC48915.2020.9156045},
	urldate = {2024-05-01},
	booktitle = {2020 {International} {Conference} on {Electronics} and {Sustainable} {Communication} {Systems} ({ICESC})},
	publisher = {IEEE},
	author = {Nihale, Shyam and Sharma, Shantanu and Parashar, Lokesh and Singh, Upendra},
	month = jul,
	year = {2020},
	pages = {338--343},
}
